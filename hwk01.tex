% Another example tex file
% Oberlin College
% Isaac Hollander McCreery

\documentclass[11pt]{amsart}

% document information
\newcommand{\hwk}{1}
\newcommand{\honor}{We affirm that we have adhered to the honor code on this assignment.}

\input{preamble}

\begin{document}
\maketitle

\section*{Part 1: Search Problem Formulation}

\begin{enumerate}

\item

\item

\item

\begin{description}

% TODO do we need to give more explanation?

\item[State space] $\{(a,b) \mid a \in \{0, \dots, 3\}, b \in \{0, \dots, 5\} \}$

\item[Start state] $(0, 0)$

\item[Available actions] from $(a, b)$:
\begin{align*}
	a &\rightarrow 0 \\
	b &\rightarrow 0
	% TODO others... are these right?
\end{align*}

\item[Successor function] the state reached by applying an available action
% TODO is this allowed? do we need more?

\item[Goal test]: is $b = 4$?

\item[Cost function]: uniform cost; any action costs 1
\end{description}

\item

\begin{description}

% TODO do we need to give more explanation?

\item[State space] $\{(t, m, b, f) \mid t, m, b, f \in \{0, 1\}\}$

\item[Start state] $(0, 0, 0, 0)$

\item[Available actions] from $(t, m, b, f)$:
\begin{align*}
	&\text{ invert $f$ (change it from 0 to 1 or from 1 to 0),} \\
	\text{if } t = f, &\text{ invert both $t$ and $f$,} \\
	\text{if } m = f, &\text{ invert both $m$ and $f$,} \\
	\text{if } b = f, &\text{ invert both $b$ and $f$}
\end{align*}

\item[Successor function] the state reached by applying an available action
% TODO is this allowed? do we need more?

\item[Goal test]: is the state $(1, 1, 1, 1)$?

\item[Cost function]: 1 if action a results in a state $(t, m, b, f)$ where $t
= m \neq f$ or where $m = b \neq f$, 0 otherwise
\end{description}

\end{enumerate}

\section*{Part 2: Heuristic Functions}

\emph{Theorem.}
If a heuristic is consistent, then it must be admissible.

\begin{proof}
Suppose that the heuristic $h: Q \rightarrow \mathbb{R}^+$, where $Q$ is the state space for a given
problem, is consistent.  Then for any $n \in Q$, $h(n) \leq c(n, a, n') + h(n')$ for all successors
$n'$ of $n$, where $c(n, a, n')$ is the cost of moving from $n$ to $n'$.  But, similarly, $h(n') \leq
c(n', a, n'') + h(n'')$ for all successors $n''$ of $n'$.  We may continue in this fashion until we
get to some successor $n^k$ that is a goal state, and whose heuristic is zero:
\[
h(n) \leq c(n, a, n') + h(n') \leq c(n, a, n') + c(n', a, n'') + h(n'') \leq \dots \leq
\sum_{i = 1}^k c(n^{i-1}, a, n^i),
\]
but one of such sums is the minimum cost path from $n$ to a goal state $n^k$, so
\[
h(n) \leq \sum_{i = 1}^k c(n^{i-1}, a, n^i) = h^*(n),
\]
and thus $h$ is admissible.
\end{proof}

\emph{Theorem.}
If a heuristic is admissible, then it is not necessarily consistent.

\begin{proof}
Consider the following example:

\vspace*{1in}

where $h(n) = 3$ and $h(n') = 1$.  Then $h(n) = 3 = h^*(n)$ and $h(n') = 1 \leq 2 = h^*(n')$,
so $h$ is admissible.  However, $h(n) = 3 \nleq 2 = c(n, a, n') + h(n')$, so $h$ is not consistent.
\end{proof}

\section*{Part 3: Advanced Search}

\subsection*{Hill-climbing}  Given a graph $G$, a state $s \subseteq V(G)$ is some clique in $G$
with at least one vertex.  A neighbor of $s$ is any $s' = s \cup \{y\} \subseteq V(G)$ where $y$ is a
neighbor of all vertices in $s$.

Start at $s = \{x\}$ for some random vertex $x \in V(G)$.  Move to any neighbor $s'$ by adding a
vertex $y$ that is a neighbor of all vertices in $s$.  Repeat until there is no neighbor $y$ to add,
and return.

\subsection*{Simulated annealing}

\subsection*{Genetic}
This genetic algorithm is not guaranteed to find a clique and likely won't.
Instead, we came up with a way of rating a graph's \emph{cliqueness}. If a
clique and had $n$ vertices, then it would necessarily have $\frac{n(n-1)}{2}$
edges. Any fewer edges means its cliqueness is less. Therefore, if a graph has $e$
edges, then a measure of its cliqueness could be $\frac{2e}{n(n-1)}$. This would be 1 if
the graph is a clique and less otherwise. To favor large cliques, our fitness
function for a given graph or sub-graph will be
\[
f(G) = \Bigg(\frac{2e}{n(n-1)}\Bigg)n.
\]

Given a graph, start with $x$ random subgraphs. Compute their fitness.
Select the two fittest subgraphs. % TODO this should be probabalistic
Mate them by selecting a random subset of the union of
the two parent subgraphs, and mutate by adding an additional random vertex.
Create $x$ off-spring this way, and repeat. Iterate until a subgraph of desirable
size and cliqueness (of desirable fitness) is found.

% TODO parameter variations

\section*{Part 4: AI in the World}

\section*{Part 5: Project Prep}

% TODO these both probably need more (why is it interesting?  why use these search techniques?)

\subsection*{Search Search}
Given a certain search problem, what annealing function finds the best solution
on average? Fix the number of search steps to $X$. Then search for the optimal
function temperature $T(t)$ where $t \leq X$. Does a linearly decreasing temperature
tend to find the best solution for a given problem.  Asymptotically
decreasing?. The state space would be different functions $T(t)$ and fitness of
that state would be the average success of that function at finding a good
solution for a particular problem. This would likely require lots of
computation, perhaps over several days. The “search search” itself could be
hill climbing, annealing, or genetic. If the T functions are encoded as
$X$-tuples $(T_1, T_2, \dots, T_X)$, then two $T$-functions could be “mated” by
combining them step-wise at $X/2$.

\subsection*{Neural Networks}
Evolve (search for) a neural network for accomplishing simple yet novel task. A
neural network can be straightforwardly modeled by a matrix (or “connectrix”)
representing synapses between neurons (edges between vertices). The state space
would be huge. A 30-neuron network would be a matrix with 900 entries. Then,
each entry would have a range of values.

The fitness of a network would be it's average success (over a fixed number of
trials) at solving a particular kind of problem such as detecting whether a
picture is of a human being or a dog's face, though even that may be too
complicated. Simulated annealing may be the best search option\----an action could
be to add or remove or change the strength of a synapse, or the firing behavior
of a neuron.

\honor

\end{document}
