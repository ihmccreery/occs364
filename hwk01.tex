% Another example tex file
% Oberlin College
% Isaac Hollander McCreery

\documentclass[11pt]{amsart}

% document information
\newcommand{\hwk}{1}
\newcommand{\honor}{We affirm that we have adhered to the honor code on this assignment.}

\input{preamble}

\begin{document}
\maketitle

\section*{Part 1: Search Problem Formulation}

\begin{enumerate}

\item

\begin{description}

\item[State space]

\item[Start state]

\item[Available actions]

\item[Successor function]

\item[Goal test]

\item[Cost function]

\end{description}

\item

\begin{description}

\item[State space]

\item[Start state]

\item[Available actions]

\item[Successor function]

\item[Goal test]

\item[Cost function]

\end{description}

\item

\begin{description}

% TODO do we need to give more explanation?

\item[State space] $\{(a,b) \mid a \in \{0, \dots, 3\}, b \in \{0, \dots, 5\} \}$

\item[Start state] $(0, 0)$

\item[Available actions] from $(a, b)$:
\begin{align*}
	a &\rightarrow 0 \\
	b &\rightarrow 0
	% TODO others... are these right?
\end{align*}

\item[Successor function] the state reached by applying an available action
% TODO is this allowed? do we need more?

\item[Goal test] is $b = 4$?

\item[Cost function] uniform cost; any action costs 1

\end{description}

\item

\begin{description}

% TODO do we need to give more explanation?

\item[State space] $\{(t, m, b, f) \mid t, m, b, f \in \{0, 1\}\}$

\item[Start state] $(0, 0, 0, 0)$

\item[Available actions] from $(t, m, b, f)$:
\begin{align*}
	&\text{ invert $f$ (change it from 0 to 1 or from 1 to 0),} \\
	\text{if } t = f, &\text{ invert both $t$ and $f$,} \\
	\text{if } m = f, &\text{ invert both $m$ and $f$,} \\
	\text{if } b = f, &\text{ invert both $b$ and $f$}
\end{align*}

\item[Successor function] the state reached by applying an available action
% TODO is this allowed? do we need more?

\item[Goal test]: is the state $(1, 1, 1, 1)$?

\item[Cost function]: 1 if action a results in a state $(t, m, b, f)$ where $t
= m \neq f$ or where $m = b \neq f$, 0 otherwise

\end{description}

\end{enumerate}

\section*{Part 2: Heuristic Functions}

\emph{Theorem.}
If a heuristic is consistent, then it must be admissible.

\begin{proof}
Suppose that the heuristic $h: Q \rightarrow \mathbb{R}^+$, where $Q$ is the state space for a given
problem, is consistent.  Then for any $n \in Q$, $h(n) \leq c(n, a, n') + h(n')$ for all successors
$n'$ of $n$, where $c(n, a, n')$ is the cost of moving from $n$ to $n'$.  But, similarly, $h(n') \leq
c(n', a, n'') + h(n'')$ for all successors $n''$ of $n'$.  We may continue in this fashion until we
get to some successor $n^k$ that is a goal state, and whose heuristic is zero:
\[
h(n) \leq c(n, a, n') + h(n') \leq c(n, a, n') + c(n', a, n'') + h(n'') \leq \dots \leq
\sum_{i = 1}^k c(n^{i-1}, a, n^i),
\]
but one of such sums is the minimum cost path from $n$ to a goal state $n^k$, so
\[
h(n) \leq \sum_{i = 1}^k c(n^{i-1}, a, n^i) = h^*(n),
\]
and thus $h$ is admissible.
\end{proof}

\emph{Theorem.}
If a heuristic is admissible, then it is not necessarily consistent.

\begin{proof}
Consider the following example:

\vspace*{1in}

where $h(n) = 3$ and $h(n') = 1$.  Then $h(n) = 3 = h^*(n)$ and $h(n') = 1 \leq 2 = h^*(n')$,
so $h$ is admissible.  However, $h(n) = 3 \nleq 2 = c(n, a, n') + h(n')$, so $h$ is not consistent.
\end{proof}

\section*{Part 3: Advanced Search}

\subsection*{Hill-climbing}  Given a graph $G$, a state $s \subseteq V(G)$ is some clique in $G$
with at least one vertex.  A neighbor of $s$ is any $s' = s \cup \{y\} \subseteq V(G)$ where $y$ is a
neighbor of all vertices in $s$.

Start at $s = \{x\}$ for some random vertex $x \in V(G)$.  Move to any neighbor $s'$ by adding a
vertex $y$ that is a neighbor of all vertices in $s$.  Repeat until there is no neighbor $y$ to add,
and return.

\subsection*{Simulated annealing}

% TODO Charlie

\subsection*{Genetic}
This genetic algorithm is not guaranteed to find a clique and likely won't.
Instead, we came up with a way of rating a graph's \emph{cliqueness}. If a
clique and had $n$ vertices, then it would necessarily have $\frac{n(n-1)}{2}$
edges. Any fewer edges means its cliqueness is less. Therefore, if a graph has $e$
edges, then a measure of its cliqueness could be $\frac{2e}{n(n-1)}$. This would be 1 if
the graph is a clique and less otherwise. To favor large cliques, our fitness
function for a given graph or sub-graph will be
\[
f(G) = \Bigg(\frac{2e}{n(n-1)}\Bigg)n.
\]

Given a graph, start with $x$ random subgraphs. Compute their fitness.
Select the two fittest subgraphs. % TODO this should be probabalistic
Mate them by selecting a random subset of the union of
the two parent subgraphs, and mutate by adding an additional random vertex.
Create $x$ off-spring this way, and repeat. Iterate until a subgraph of desirable
size and cliqueness (of desirable fitness) is found.

% TODO parameter variations

\section*{Part 4: AI in the World}

\subsection*{Evolutionary Algorithm for Decryption of Monoalphabetic Homophonic
Substitution Ciphers Encoded as Constraint Satisfaction Problems: David
Oranchak}

A homophonic substitution cipher is an encryption which maps each plaintext
character in a message to one or more ciphertext symbols.  This type of
encryption is much more difficult to decode than a monoalphabetic cipher, which
is one in which each plain text letter is mapped to exactly one ciphertext
letter.  David Oranchak uses a genetic algorithm in order to decipher
homophonic substitution ciphers.  First, the algorithm finds the segment of the
cipher in which the highest concentration of different cipher-text letters are
(i.e.\ A portion such that (the number of unique ciphertext symbols in that
section divided by the number of total unique ciphertext symbols in the entire
message) is maximized). The population is a set of words from a dictionary
(i.e.\ the english language) and the selected high-concentration of the
cyphertext is matched up with these words, to check to see if it is a good
match.  Oranchak defined two fitness functions.  The first fitness function was
a measure of how many of the words outside of the high concentration section
are actual words in the dictionary.  The second fitness function is measured by
building a graph $G$ and letting each vertex be a found word in the cypher
text.  For every conflict, in which two words do not match due to the
cyphertext, an edge is placed between those vertices.  The second fitness
function is a measure of the number of edges between the vertices, with fewer
edges being proportional to higher fitness.  The merging process is done by
running tournament selection of size two, with a small probability of selecting
the less fit of the pair.  When parents merge, random character selections are
swapped and there is a small chance of mutation.  The algorithm precisely
decoded the Zodiac Killers homophonic substitution cipher.

\subsection*{Using a genetic algorithm to determine StarCraft 2 build orders}

In the game StarCraft 2, before interacting with the "enemy" you as the player
have time to run a series of build orders.  Those build orders will determine
how many of all your things and people you have and will thus determine how you
are able to interact with your enemies.  In this genetic algorithm, the
population is a set of build orders and the fitness function is how close that
set of build orders gets you to some desired outcome.  This algorithm ignores
all sets of build orders with a fitness of 0, which implies that the build
orders are an invalid sequence.  The algorithm takes the most fit sets of build
orders and combines them by concatenating sub-sets of them together.  There is
also the chance of mutation, including insertion and deletion of a build order.
In the end, the algorithm spits out the most fit set of build orders.  One of
the pro's of this algorithm is that it might possibly give you an excellent
SC2 opening strategy, and you wouldn't have to think about it at all.
However, the fitness test is based upon reaching a "desired" state, which must
be a subjectively chosen state, which means that that state isn't globally
optimal.  This algorithm did come up with an extremely unorthodox strategy
though which turned out to be extremely effective and nearly unbeatable.

\emph{Source.} \texttt{http://lbrandy.com/blog/2010/11/using-genetic-algorithms-to-find-starcraft- 2-build-orders/}

\section*{Part 5: Project Prep}

% TODO these both probably need more (why is it interesting?  why use these search techniques?)

\subsection*{Search Search}
Given a certain search problem, what annealing function finds the best solution
on average? Fix the number of search steps to $X$. Then search for the optimal
function temperature $T(t)$ where $t \leq X$. Does a linearly decreasing temperature
tend to find the best solution for a given problem.  Asymptotically
decreasing?. The state space would be different functions $T(t)$ and fitness of
that state would be the average success of that function at finding a good
solution for a particular problem. This would likely require lots of
computation, perhaps over several days. The “search search” itself could be
hill climbing, annealing, or genetic. If the T functions are encoded as
$X$-tuples $(T_1, T_2, \dots, T_X)$, then two $T$-functions could be “mated” by
combining them step-wise at $X/2$.

\subsection*{Neural Networks}
Evolve (search for) a neural network for accomplishing simple yet novel task. A
neural network can be straightforwardly modeled by a matrix (or “connectrix”)
representing synapses between neurons (edges between vertices). The state space
would be huge. A 30-neuron network would be a matrix with 900 entries. Then,
each entry would have a range of values.

The fitness of a network would be it's average success (over a fixed number of
trials) at solving a particular kind of problem such as detecting whether a
picture is of a human being or a dog's face, though even that may be too
complicated. Simulated annealing may be the best search option\----an action could
be to add or remove or change the strength of a synapse, or the firing behavior
of a neuron.

\honor

\end{document}
